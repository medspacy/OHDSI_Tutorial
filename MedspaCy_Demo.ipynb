{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "MedspaCy-Demo.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/medspacy/OHDSI_Tutorial/blob/master/MedspaCy_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOgXTE098gzy"
      },
      "source": [
        "# MedspaCy OHDSI Tutorial\n",
        "This notebook introduces [**medspaCy**](https://github.com/medspacy/medspacy). We start with a quick overview of the goals of medspaCy and how it can be used in clinical NLP. We then go step-by-step through a typical clinical NLP workflow and show how each of the components of medspaCy can be used to etract information from clinical text.\n",
        "\n",
        "If you would like to follow along, this Colab notebook is available at:\n",
        "\n",
        "[tinyurl.com/OHDSI-medspacy](\n",
        "https://tinyurl.com/OHDSI-medspacy)\n",
        "\n",
        "or on the medspaCy github:\n",
        "\n",
        "[github.com/medspacy/OHDSI_Tutorial](https://github.com/medspacy/OHDSI_Tutorial)\n",
        "\n",
        "First, we'll get set up by installing medspaCy and some pre-trained spaCy models. If you don't already have these installed, you may have to restart your kernel before you can load them:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqIejlSW8gz3"
      },
      "source": [
        "# install medspaCy and dependencies\n",
        "!pip install medspacy==0.1.0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwWa9zcC8gz4"
      },
      "source": [
        "# Install a general english language model\n",
        "!python -m spacy download \"en_core_web_sm\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2zqm6bO8gz4"
      },
      "source": [
        "# Install a pre-trained clinical NER model\n",
        "!pip install https://github.com/abchapman93/spacy_models/raw/master/releases/en_info_3700_i2b2_2012-0.1.0/dist/en_info_3700_i2b2_2012-0.1.0.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fGNcAmi8gz4"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('once')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptLoM44P8gz5"
      },
      "source": [
        "# Outline\n",
        "**I. Background**\n",
        "\n",
        "Covers why we chose to develop medspaCy and what it is meant to do.\n",
        "\n",
        "**II. Quick Overview of spaCy**\n",
        "\n",
        "Shows basic features of spacy to establish shared vocabulary between spacy and medspaCy as well as explain some medspaCy API decisions.\n",
        "\n",
        "**III. Clinical NLP  with medspaCy**\n",
        "\n",
        "An overview of some of the basic features of medspacy.\n",
        "\n",
        "**IV. Future Work and Additional Info**\n",
        "\n",
        "Discuss development direction, goals, and open the presentation questions or discussions on new or existing features and use cases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZNRuaBI8gz5"
      },
      "source": [
        "# Background\n",
        "![MedspaCy logo](https://github.com/medspacy/medspacy/blob/master/images/medspacy_logo.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7OW4sfM-Qfr"
      },
      "source": [
        "## Why Python?\n",
        "\n",
        "Python is has become the dominant programming language for data science and natural language processing (NLP). Most of the largest open-source data science projects are developed in Python and some of these projects are among the most active open-source projects ever. Tensorflow had over 11,000 unique contributors in 2020 alone.\n",
        "\n",
        "Many of the largest clinical natural langauge processing projects and frameworks are in Java, so for the clinical NLP community to use the work of the large Python data science development community, adoption of Python is needed. However, many projects in Python for clinical or biomedical NLP are developed for specific projects, research groups or for redistributing models trained for specific tasks, making widespread code-reuse low.\n",
        "\n",
        "We have developed medspaCy specifically to meet this need. medspaCy is a library of tools for performing clinical NLP and text processing tasks with the popular [spaCy](spacy.io) framework. medspaCy is designed to unify a many of the most common clinical text processing algorithms (context analysis, secton detection, UMLS mapping, etc.) into one API and style.\n",
        "\n",
        "medspaCy aims to allow for the seamless integration of essential rule-based clinical NLP methods with the growing capabilities of the most popular Python libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YghQybbd9eFe"
      },
      "source": [
        "## medspaCy is...\n",
        "\n",
        "### ... a toolkit\n",
        "Unlike other libraries like [scispaCy](https://allenai.github.io/scispacy/) and [medCAT](https://github.com/CogStack/MedCAT), the main goal of medspaCy is not necessarily to implement pre-trained clinical models. Instead, medspaCy is a toolkit for designing user-specific clinical NLP pipelines. medspaCy offers a number of rule-based components which allow users to easily write rules to extract specific concepts, but can be integrated with more sophisticated techniques from other sources.\n",
        "\n",
        "### ... good for prototypes and rapid development\n",
        "medspaCy facilitates rapid development by offering default configurations for all components so everything works out-of-the-box. It also works well with interactive development tools like visualization and working in jupyter notebooks.\n",
        "\n",
        "medspaCy is simple to install and requires no admin privileges to get an environment set up on a computer.\n",
        "\n",
        "### ... customizable\n",
        "All clinical data differs and no two clinical NLP tasks are the same. medspaCy components can be easily customized with user-defined rules. One of the main advantages of spaCy is its flexible architecture, which allows you to mix and match different models and components. Similarly with medspaCy, you can add components to existing pipelines, including statistical models trained using spaCy or other frameworks.\n",
        "\n",
        "### ... compatible with other spaCy projects\n",
        "medspaCy components do not add extra layers to the spaCy API, allowing medspaCy components to be used alongside other components, such as those from libraries like scispaCy or any custom components developed for a specific task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oV1aiGk48gz6"
      },
      "source": [
        "## How is medspaCy used?\n",
        "\n",
        "### medspaCy team's projects\n",
        "\n",
        "medspaCy has been used in many VA operational and research projects such as:\n",
        "- [VA COVID-19 Surveillance](https://www.aclweb.org/anthology/2020.nlpcovid19-acl.10/): An operational pipeline for identifying COVID positive cases in the Department of Veterans Affairs\n",
        "- Processing COVID-19 screening questionnaires for symptoms\n",
        "- Veteran homelessness and housing stability\n",
        "- Templated document processing\n",
        "\n",
        "### Outside projects\n",
        "medspaCy has been used in a small but growing list of external projects. It has a wrapper, visualization app, and a few community projects. We would like to keep a list of outside users and projects available, so if you have something we can link to, get in touch!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvNmnsUe8gz6"
      },
      "source": [
        "# Quick overview of spaCy\n",
        "\n",
        "We will *very* briefly go over basic features of spaCy to make sure some medspaCy terminology is established.\n",
        "\n",
        "More in-depth resources for spaCy usage is available at the [project website](spacy.io) and [online course](https://course.spacy.io/en/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlHV5vkH8gz6"
      },
      "source": [
        "## Getting Started\n",
        "\n",
        "The first step is always importing the library you want to use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THVZS8C_8gz6"
      },
      "source": [
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FXdLH9m8gz7"
      },
      "source": [
        "## Loading a spaCy model\n",
        "\n",
        "Like medspaCy, spaCy is a primarily a toolkit and framework. It does not have any data after installing and importing it.\n",
        "\n",
        "The spaCy developers and community distribute a large variety of models for different tasks. Each model is named according to the language, use case, training source, and size.\n",
        "\n",
        "At the top of this notebook, we installed a spaCy model using this command:\n",
        "```bash\n",
        "python -m spacy download \"en_core_web_sm\"\n",
        "```\n",
        "\n",
        "`en_core_web_sm` is one of the basic spacy models: `en` English, `core` core/general use, `web` trained on internet data, `sm` in a small size.\n",
        "\n",
        "These spaCy-distributed models are simple to load. The `load` method accesses a registry of installed models by name.\n",
        "\n",
        "Loading the model involves opening vocabulary files, pre-trained weights, and other resouces and using them to initialize components saved in a spacy pipeline object typically named `nlp`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS2foci38gz7"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stHzfps_8gz8"
      },
      "source": [
        "The `en_core_web_sm` model loads a part-of-speech tagger, a dependency parser (with sentence splitting), and a named entity recognition component with the OntoNotes labels (PER, GPE, DATE, CARDINAL, etc.).\n",
        "\n",
        "Every spaCy pipeline includes a tokenizer, but it is not visible or easily altered because it is the foundation all of spaCy's other components."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ROI-0uj8gz8"
      },
      "source": [
        "nlp.pipe_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5HV-Utt8gz8"
      },
      "source": [
        "## Using a spaCy pipeline\n",
        "\n",
        "`nlp` is a callable object and takes in the text to process. It applies each component in `nlp` sequentially. \n",
        "\n",
        "So in our case `tokenizer` to `tagger` to `parser` to `ner`.\n",
        "\n",
        "Because these spaCy models are designed for general English text, our example will be the first sentence of a recent [New York Times article](https://www.nytimes.com/live/2021/03/02/world/covid-19-coronavirus/biden-says-there-will-be-enough-vaccine-available-for-all-adults-by-the-end-of-may-as-johnson-johnson-makes-a-deal-to-boost-supp)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0XmnqRN8gz8"
      },
      "source": [
        "text = \"President Biden announced Tuesday that there would be \\\n",
        "enough doses of the coronavirus vaccine available for the \\\n",
        "entire adult population in the United States by the end of \\\n",
        "May, though he said it will take longer to inoculate everyone \\\n",
        "and he urged people to remain vigilant by wearing masks.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wc-ClYjP8gz8"
      },
      "source": [
        "A spaCy `Doc` object is returned when processing is done. A `Doc` is just a container for the results of any spaCy pipeline. These are usually called `doc`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScJlH5LQ8gz9"
      },
      "source": [
        "doc = nlp(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoQspw_F8gz9"
      },
      "source": [
        "## Using the results\n",
        "\n",
        "`doc` will have certain properties that allow you to see the results of the processing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrbTTZ0q8gz9"
      },
      "source": [
        "doc.ents"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cocrTho38gz9"
      },
      "source": [
        "Like `Doc`, spaCy also has containers for results at a more specific level: `Token` and `Span`. To use `Token` and `Span` objects, `doc` is accessed like a Python list. \n",
        "\n",
        "For example, we can look at the `Token` at index 1 of `doc`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFamCb9a8gz9"
      },
      "source": [
        "doc[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTMtlAes8gz-"
      },
      "source": [
        "type(doc[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_4wynX78gz-"
      },
      "source": [
        "doc[1].pos_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_45sp7aQ8gz-"
      },
      "source": [
        "## Visualizing the results \n",
        "\n",
        "spaCy also includes some tools for visualization. `displaCy` is a spacy module that can display entities and dependency results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_MY2eZi8gz-"
      },
      "source": [
        "from spacy import displacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKML5MSx8gz-"
      },
      "source": [
        "displacy.render(doc, style='ent', jupyter=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6VLt-gx8gz-"
      },
      "source": [
        "displacy.render(doc, style='dep', jupyter=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbbdizQp8gz_"
      },
      "source": [
        "## More spaCy resources\n",
        "- [spaCy documentation](https://spacy.io/)\n",
        "- [A free online course](https://course.spacy.io/en/) from the makers of spaCy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSzIX_5z8gz_"
      },
      "source": [
        "# II. Clinical NLP with medspaCy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PscPFzMQ8gz_"
      },
      "source": [
        "## Getting Started with medspaCy\n",
        "\n",
        "You can install medspaCy using pip:\n",
        "```bash\n",
        "!pip install medspacy==0.1.0.2\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQD6sgBQ8gz_"
      },
      "source": [
        "To get started with medspaCy, you can load a pipeline by calling `medspacy.load()`. By default, this will load the following 3 pipeline components:\n",
        "- `PyRuSHSentencizer`: Uses [PyRuSh](https://github.com/jianlins/PyRuSH) for clinical sentence segmentation\n",
        "- `TargetMatcher`: A rule-based concept extractor\n",
        "- `ConTextComponent`: An implementation of the [ConText](https://pubmed.ncbi.nlm.nih.gov/19435614/) algorithm for detecting attributes like negation and temporality\n",
        "\n",
        "You can also start a medspaCy pipeline by loading `en_core_web_sm` or any other spaCy model, but keep in mind the domain limitations of components like NER using OntoNotes labels for clinical text.\n",
        "\n",
        "Throughout this notebook, we'll customize these components as well as add new ones for additional processing steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZuKu3Kq8gz_"
      },
      "source": [
        "import medspacy\n",
        "nlp = medspacy.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXd2kfhy8gz_"
      },
      "source": [
        "nlp.pipe_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTVypuS18gz_"
      },
      "source": [
        "def read_discharge_summary():\n",
        "    url = \"https://raw.githubusercontent.com/medspacy/OHDSI_Tutorial/master/discharge_summary.txt\"\n",
        "    import urllib\n",
        "\n",
        "    with urllib.request.urlopen(url) as f:\n",
        "        text = f.read().decode()\n",
        "    return text\n",
        "\n",
        "text = read_discharge_summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFw5l5XC8g0A"
      },
      "source": [
        "print(text[:500])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpUIOAaa8g0A"
      },
      "source": [
        "Just like a normal spaCy model, you process a text by calling `nlp(text)`, which returns a `Doc` object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWX24suS8g0A"
      },
      "source": [
        "doc = nlp(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu2i98468g0A"
      },
      "source": [
        "## Common Clinical NLP Tasks and medspaCy\n",
        "medspaCy is built as a modular set of **pipeline components** which handle a specific NLP task. Because of spaCy's flexible framework, you can easily add new components, including pre-trained or custom models.\n",
        "\n",
        "In this notebook, we'll walk through the following processing steps:\n",
        "- **Rule-Based Concept Extraction**\n",
        "- **Statistical NER**\n",
        "- **Contextual Analysis**\n",
        "- **Section Detection**\n",
        "- **Input/Output**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WysqziS28g0A"
      },
      "source": [
        "## Rule-Based Concept Extraction\n",
        "In this step, we'll manually define rules to extract clinical concepts from the text.\n",
        "\n",
        "In this example, we'll use two classes provided in `medspacy.ner` for rule-based matching: the `TargetMatcher` and `TargetRule`. These expand on spaCy's native [rule-based matching](https://spacy.io/usage/rule-based-matching) and add some additional functionality.\n",
        "\n",
        "When `TargetRule` processes a doc, it adds the matched span to `doc.ents`, which contains all of the extracted entities for a doc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASzbqQSD8g0A"
      },
      "source": [
        "from medspacy.ner import TargetMatcher, TargetRule"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TP6Y3_6I8g0A"
      },
      "source": [
        "target_matcher = nlp.get_pipe(\"target_matcher\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zkf14DxB8g0A"
      },
      "source": [
        "We define a rule for extracting entities with the `TargetRule` class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNcHT50o8g0B"
      },
      "source": [
        "target_rules = [\n",
        "    TargetRule(literal=\"abdominal pain\", category=\"PROBLEM\"),\n",
        "    TargetRule(\"stroke\", \"PROBLEM\"),\n",
        "    TargetRule(\"hemicolectomy\", \"TREATMENT\"),\n",
        "    TargetRule(\"Hydrochlorothiazide\", \"TREATMENT\"),\n",
        "    TargetRule(\"colon cancer\", \"PROBLEM\"),\n",
        "    TargetRule(\"metastasis\", \"PROBLEM\"),\n",
        "    \n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1RVb7sP8g0B"
      },
      "source": [
        "target_matcher.add(target_rules)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFSKoo8t8g0B"
      },
      "source": [
        "doc = nlp(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqDawMsG8g0B"
      },
      "source": [
        "for ent in doc.ents:\n",
        "    print(ent, ent.label_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoEotnsN8g0B"
      },
      "source": [
        "from medspacy.visualization import visualize_ent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "G5V_flwW8g0B"
      },
      "source": [
        "visualize_ent(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4WHELff8g0B"
      },
      "source": [
        "### Advanced Rule-Based Concept Extraction\n",
        "SpaCy has powerful pattern matching which allows you to match on a list of dictionaries which define attributes for each token. See https://spacy.io/usage/rule-based-matching for spaCy's documentation and examples. Additionally, medspaCy allows matching with regular expressions on the underlying text of the doc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxDcvbNP8g0C"
      },
      "source": [
        "pattern_rules = [\n",
        "    # Using spaCy's dictionary token patterns\n",
        "    TargetRule(\"Acetaminophen\", \"TREATMENT\",\n",
        "               pattern=[\n",
        "                   {\"LOWER\": {\"IN\": [\"acetaminophen\", \"tylenol\"]}},\n",
        "                   {\"LIKE_NUM\": True, \"OP\": \"?\"},\n",
        "                   {\"LOWER\": \"mg\", \"OP\": \"?\"}\n",
        "               ],\n",
        "              ),\n",
        "    \n",
        "    # Using regular expressions\n",
        "    TargetRule(\"diabetes\", \"PROBLEM\",\n",
        "              pattern=r\"type (i|ii|1|2|one|two) (dm|diabetes mellitus)\"),\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhZhbtxB8g0C"
      },
      "source": [
        "target_matcher.add(pattern_rules)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hERDXzqc8g0C"
      },
      "source": [
        "sm_text = \"\"\"\n",
        "    Discharge Medications: Acetaminophen 160 mg\n",
        "    Prescribed tylenol for the pain\n",
        "    74y female with type 2 dm and a recent stroke.\n",
        "    Diagnoses: Type II Diabetes Mellitus\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcB_YlfU8g0C"
      },
      "source": [
        "sm_doc = nlp(sm_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvNEZWy28g0C"
      },
      "source": [
        "for ent in sm_doc.ents:\n",
        "    print(ent, ent.label_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4ji5ByT8g0C"
      },
      "source": [
        "visualize_ent(sm_doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srzUBRDm8g0C"
      },
      "source": [
        "## Statistical NER\n",
        "While rule-based models are still very useful in clinical NLP, many systems are designed as **statistical model**. In this section, we'll show how to use a pre-trained model for target concept extraction instead of defining rules. We'll then add our additional components to show how medSpaCy can be used to combine statistical NLP with other rule-based components.\n",
        "\n",
        "As an example, we'll download the model below which contains a model pretrained for clinical data. This model was trained using spaCy with data from the i2b2 2012 shared task: [**\"Evaluating temporal relations in clinical text\"**](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3756273/).\n",
        "\n",
        "We installed this model at the beginning of this notebook with `pip`:\n",
        "```bash\n",
        "pip install https://github.com/abchapman93/spacy_models/raw/master/releases/en_info_3700_i2b2_2012-0.1.0/dist/en_info_3700_i2b2_2012-0.1.0.tar.gz\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf3FI3CcCCnz"
      },
      "source": [
        "NOTE: The following cell might cause an error. The pre-trained model is sometimes not registered with spaCy/medspaCy, when pip installing in an interactive python environment.\n",
        "\n",
        "This is resolved by going to \"Runtime\" > \"Restart\" in Colab or \"Kernel\" > \"Restart\" in Jupyter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkAnY8_b8g0D"
      },
      "source": [
        "nlp = medspacy.load(\"en_info_3700_i2b2_2012\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1t0I-D48g0D"
      },
      "source": [
        "Now let's reprocess our text and see what our pre-trained model extracts:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYclsbul8g0D"
      },
      "source": [
        "doc = nlp(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "NBzz3aql8g0D"
      },
      "source": [
        "visualize_ent(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnDbVF218g0D"
      },
      "source": [
        "The model extracted many more concepts, but missed some of the spans we defined earlier, like **\"type ii diabetes\"**. Luckily, we can combine statistical and rule-based models by adding the rules we defined to the `TargetMatcher` component."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENGWFM-g8g0D"
      },
      "source": [
        "target_matcher = nlp.get_pipe(\"target_matcher\")\n",
        "target_matcher.add(target_rules)\n",
        "target_matcher.add(pattern_rules)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csYeE_Br8g0E"
      },
      "source": [
        "doc = nlp(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "MqnOcmDV8g0E"
      },
      "source": [
        "visualize_ent(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNLVN45Y8g0E"
      },
      "source": [
        "## ConText\n",
        "\n",
        "Clinical text often contains mentions of concepts which the patient did not actually experience. For example:\n",
        "\n",
        "- \"There is *no evidence of* **pneumonia**\"\n",
        "- \"*Mother* with **breast cancer**\"\n",
        "- \"Patient presents for *r/o* **COVID-19**\"\n",
        "\n",
        "In all of these instances, we need to use the contextual clues around the entity to assert attributes like negation, experiencer, and uncertainty.\n",
        "\n",
        "The [ConText algorithm](https://www.sciencedirect.com/science/article/pii/S1532046409000744) is a popular method for asserting attributes of entities in clinical text such as **negation**, **temporality**, and **experiencer**. ConText is implemented in medspaCy using the `ConTextComponent`, which is loaded as part of a standard model.\n",
        "\n",
        "We can inspect the modifier-entity relationships using medspaCy's `visualize_dep` function, which draws arrows between modifiers and the entities that they modify."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7opnGb9J8g0E"
      },
      "source": [
        "from medspacy.visualization import visualize_dep"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_juRPeQK8g0E"
      },
      "source": [
        "doc = nlp(\"There is no evidence of pneumonia.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv1-p7yR8g0E"
      },
      "source": [
        "visualize_dep(doc)\n",
        "visualize_ent(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l0XTWrH8g0F"
      },
      "source": [
        "doc = nlp(\"Mother with stroke at age 82.\")\n",
        "visualize_dep(doc)\n",
        "visualize_ent(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaoFxCKj8g0F"
      },
      "source": [
        "In addition to linking entities and modifiers, ConText also sets a number of boolean attributes indicating whether the entity is negated, experienced by someone else, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_0-IevG8g0F"
      },
      "source": [
        "ent = doc.ents[0]\n",
        "print(ent, \"is_family\", ent._.is_family)\n",
        "print(ent,  \"is_negated\", ent._.is_negated)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n20SIl_v8g0F"
      },
      "source": [
        "### Customizing ConText\n",
        "When you load ConText in medspaCy, it comes with a default set of rules. However, you'll often need to add new rules to match your data or implement new categories.\n",
        "\n",
        "Custom modifiers can be defined using the `ConTextRule` class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpKXMvx78g0F"
      },
      "source": [
        "from medspacy.context import ConTextRule"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUPnCeTK8g0F"
      },
      "source": [
        "context = nlp.get_pipe(\"context\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRW-nACY8g0G"
      },
      "source": [
        "context_rule = ConTextRule(\"diagnosed in <YEAR>\", \"HISTORICAL\",\n",
        "                           direction=\"BACKWARD\",\n",
        "                          pattern=r\"(diagnosed|dx'd) in (19|20)[\\d]{2}\"\n",
        "                           \n",
        "                          )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lbf-D4It8g0G"
      },
      "source": [
        "context.add(context_rule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rx4A5_f8g0G"
      },
      "source": [
        "short_doc = nlp(\"Colon cancer diagnosed in 2012\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjh6Z-sg8g0G"
      },
      "source": [
        "visualize_dep(short_doc)\n",
        "visualize_ent(short_doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb59wapq8g0G"
      },
      "source": [
        "## Section detection\n",
        "We are often interested in which section of a clinical note an entity occurs in. This can be useful for excluding entities from certain sections, like the past medical history or problem list, setting attributes like temporality (similar to ConText), or for extracting entities from specific sections of the note.\n",
        "\n",
        "medspaCy includes the `Sectionizer` class for identifying sections in a note."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2T8T5Bj8g0G"
      },
      "source": [
        "from medspacy.section_detection import Sectionizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNT1LLAg8g0G"
      },
      "source": [
        "sectionizer = Sectionizer(nlp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ0X5WG88g0G"
      },
      "source": [
        "nlp.add_pipe(sectionizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LjcYt8g8g0H"
      },
      "source": [
        "doc = nlp(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBZY-3Tn8g0H"
      },
      "source": [
        "medspaCy will visualize the sections along with entities and modifiers in gray highlighting with **<\\< \\>>** tags:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "fONUJJTe8g0H"
      },
      "source": [
        "visualize_ent(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXsOXAf-8g0H"
      },
      "source": [
        "We can see the normalized section name for each entity as well:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAny6Ebj8g0H"
      },
      "source": [
        "for ent in doc.ents[:10]:\n",
        "    print(ent, \"-->\", ent._.section_category)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaY7dSBc8g0H"
      },
      "source": [
        "### Custom Section Detection\n",
        "Note structures vary widely between different EHRs and institutions, so it's important to define sections which match your note structure. The `SectionRule` defines sections to extract, and follows the same API as `TargetRule` and `ConTextRule`.\n",
        "\n",
        "Here we'll add a rule to create a **patient_demographics** section around the patient DOB:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0agC-frE8g0H"
      },
      "source": [
        "from medspacy.section_detection import SectionRule"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNbI9UrI8g0H"
      },
      "source": [
        "rule = SectionRule(\"Date of Birth:\", \"patient_demographics\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wgx0V4IO8g0I"
      },
      "source": [
        "sectionizer.add(rule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtV6In5j8g0I"
      },
      "source": [
        "visualize_ent(nlp(text[:200]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-z9p2ok8g0I"
      },
      "source": [
        "## Input/Output\n",
        "Finally, once we've processed a text or corpus, we'll want to save our extracted data to disk or a database. The `medspacy.io` module has utilities for converting docs to structured data.\n",
        "\n",
        "### Extracting Structured Data\n",
        "First, the `DocConsumer` will take various levels of information from a doc and generate structured data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN0TLg5h8g0I"
      },
      "source": [
        "from medspacy.io import DocConsumer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N2vG24ZD4mQ"
      },
      "source": [
        "The `DocConsumer` will add structured data as a dictionary to the `doc._.data` attribute, which contains one key for each level: \n",
        "* `ent` or entities\n",
        "* `context` for ConText modifiers\n",
        "* `section` for section title and body\n",
        "* `doc` for document level attributes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t5Ndx3W8g0I"
      },
      "source": [
        "doc_consumer = DocConsumer(nlp, dtypes=(\"ent\", \"context\", \"section\", \"doc\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyaDLiEQ8g0I"
      },
      "source": [
        "nlp.add_pipe(doc_consumer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z6T3Lgy8g0I"
      },
      "source": [
        "doc = nlp(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5kdxFohE-kS"
      },
      "source": [
        "The dictionary inside `doc._.data` is large and does not support convenient printing, so this code is commented out by default and we will examine the output with `pandas` instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtt3OiX98g0I"
      },
      "source": [
        "# doc._.data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBh6nQpb8g0K"
      },
      "source": [
        "If you have `pandas` installed, you can then directly convert a doc to a dataframe, which shows the attributes extracted for each entity:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrFO8LG98g0K"
      },
      "source": [
        "# !pip install pandas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6zLQwO98g0K"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkBpL8Zx8g0K"
      },
      "source": [
        "doc._.to_dataframe(\"ent\").head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "W7RzXyzS8g0K"
      },
      "source": [
        "doc._.to_dataframe(\"section\").head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyocOrxJ8g0K"
      },
      "source": [
        "doc._.to_dataframe(\"context\").head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuQiKUsD8g0L"
      },
      "source": [
        "doc._.to_dataframe(\"doc\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "---dtB4B8g0L"
      },
      "source": [
        "### Reading and Writing to a Database\n",
        "As a final step, we'll write this structured data to a database. The `DbConnect`, `DbReader` and `DbWriter` classes will handle connecting to a database, creating tables, and inserting doc data for us. \n",
        "\n",
        "Currently, medspaCy database classes support `sqlite3` or `pyodbc` databases. The function below will create a simple sqlite database which includes our discharge summary and a few additional short texts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzH49cZ28g0L"
      },
      "source": [
        "def create_medspacy_demo_db(drop_existing=True):\n",
        "    import os\n",
        "    if drop_existing is False and os.path.exists(\"medspacy_demo.db\"):\n",
        "        print(\"File medspacy_demo.db already exists\")\n",
        "        return\n",
        "    \n",
        "    text = read_discharge_summary()\n",
        "\n",
        "    import sqlite3 as s3\n",
        "\n",
        "    texts = [\n",
        "        \"There is no evidence of pneumonia.\",\n",
        "        \"Her mother was diagnosed with breast cancer.\",\n",
        "        text,\n",
        "        \n",
        "    ]\n",
        "\n",
        "    conn = s3.connect(\"medspacy_demo.db\")\n",
        "\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"DROP TABLE IF EXISTS texts;\")\n",
        "    cursor.execute(\"CREATE TABLE texts (text_id INTEGER PRIMARY KEY, text NOT NULL);\")\n",
        "\n",
        "    for text in texts:\n",
        "        cursor.execute(\"INSERT INTO texts (text) VALUES (?)\", (text,))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    print(\"Created file medspacy_demo.db\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIcEEj3a8g0L"
      },
      "source": [
        "create_medspacy_demo_db(drop_existing=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7GQTjjg8g0L"
      },
      "source": [
        "First, we'll create a connection to our database using `sqlite3` and medspaCy's `DbConnect` class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw593kmv8g0L"
      },
      "source": [
        "from medspacy.io import DbConnect"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGvd5kEP8g0L"
      },
      "source": [
        "import sqlite3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKqwJJTH8g0L"
      },
      "source": [
        "sq_conn = sqlite3.connect(\"medspacy_demo.db\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sATlkCWR8g0M"
      },
      "source": [
        "conn = DbConnect(conn=sq_conn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eg60jF1q8g0M"
      },
      "source": [
        "Next, we'll define a query to load our texts and pass it into a `DbReader` class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie4b7fv18g0M"
      },
      "source": [
        "from medspacy.io import DbReader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOCB-b6B8g0M"
      },
      "source": [
        "# Pass in our connection and a query to read texts:\n",
        "read_query = \"\"\"\n",
        "SELECT text\n",
        "FROM texts\n",
        "\"\"\"\n",
        "reader = DbReader(conn, read_query)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZN1NLUD8g0M"
      },
      "source": [
        "texts = [r[0] for r in reader.read()] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfK0wdtM8g0M"
      },
      "source": [
        "Finally, we'll process our texts, create a `DbWriter` object, and then write the extracted entities back to the database:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmmFHxmq8g0M"
      },
      "source": [
        "docs = list(nlp.pipe(texts))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4uQHem78g0M"
      },
      "source": [
        "from medspacy.io import DbWriter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CduxcMfB8g0N"
      },
      "source": [
        "writer = DbWriter(conn, destination_table=\"ents\", create_table=True, drop_existing=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvnXVdJd8g0N"
      },
      "source": [
        "for doc in docs:\n",
        "    writer.write(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1oOrnXm8g0N"
      },
      "source": [
        "Now, we have a structured dataset that we can query and analyze:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4prFBhCK8g0N"
      },
      "source": [
        "cursor = sq_conn.cursor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8BlciYR8g0N"
      },
      "source": [
        "cursor.execute(\"SELECT label_, COUNT(1) FROM ents GROUP BY label_;\")\n",
        "cursor.fetchall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G04bMM8d8g0N"
      },
      "source": [
        "# Find examples of family history\n",
        "cursor.execute(\"SELECT text, label_ FROM ents WHERE is_family = 1 LIMIT 5; \")\n",
        "cursor.fetchall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d59NKzIk8g0O"
      },
      "source": [
        "# Find examples of family history\n",
        "cursor.execute(\"SELECT text, label_ FROM ents WHERE text LIKE '%cancer%' LIMIT 5; \")\n",
        "cursor.fetchall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdNITe5j8g0O"
      },
      "source": [
        "# III. Future Work and Additional Information\n",
        "We are still actively working on medspaCy and are continually making updates. Some of our immediate next steps are:\n",
        "- Support for spaCy v3\n",
        "- Better documentation\n",
        "- Release trained models/pipelines\n",
        "- More utilities for machine learning\n",
        "- New features?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuaKd4DI8g0O"
      },
      "source": [
        "## medspaCy resources\n",
        "- [medspaCy on GitHub](https://github.com/medspacy/medspacy)\n",
        "- [Detailed notebooks and tutorials](https://github.com/medspacy/medspacy/tree/master/notebooks)\n",
        "- [A workshop from the University of Melbourne](https://github.com/Melbourne-BMDS/mimic34md2020_materials) on clinical data science including medspaCy\n",
        "## Publications\n",
        "* ACL COVID-19 Workshop: [A Natural Language Processing System for National COVID-19 Surveillance in the US Department of Veterans Affairs](https://www.aclweb.org/anthology/2020.nlpcovid19-acl.10/)\n",
        "* AMIA Poster: [Removing barriers to clinical text processing with MedSpaCy](https://knowledge.amia.org/72332-amia-1.4602255/t005-1.4604904/t005-1.4604905/3414620-1.4605626/3414620-1.4605627?qr=1)\n",
        "* AMIA 2021 Paper (submitted, arXiv link possibly coming soon)\n",
        "* AMIA Tutorial 2021 (submitted)"
      ]
    }
  ]
}
